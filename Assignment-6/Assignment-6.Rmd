---
title: "Assignment 6: ATAC-seq"
output:
  github_document:
  toc: true
toc_depth: 4
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment overview

*Today we will be looking at a differential ATAC-seq dataset between cells treated with an anti BAF protac and control (untreated) cells. The cell type is HAP1, a cancer cell line with a near-haploid genome. We will use this dataset to explore differential analysis. *
  
  *The GEO entry is located here, where you can read more about the experiments: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE148175 *
  
  *This is the paper: https://www.nature.com/articles/s41588-021-00777-3 *
  
  *"Acute BAF perturbation causes immediate changes in chromatin accessibility"*
  
  
  
  # Part 0: Getting ready 
  
```{r}
#install any of these you might not have already
library(ggplot2)
library(edgeR)
library(reshape)
library(GenomicRanges)
library(csaw)
library(Biostrings)
library(tidyr)
```


```{r}
#download the data
atacSeqData = read.table(textConnection(readLines(gzcon(url("ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE148nnn/GSE148175/suppl/GSE148175_count_matrix_raw_atac_BRM014_ACBI1.csv.gz")))), 
                         sep=",", stringsAsFactors = FALSE, header = TRUE)
```


```{r}
#create a sample metadata data.frame
samples = data.frame(ID = names(atacSeqData)[2:ncol(atacSeqData)])
samples$replicate = gsub("(R[12])_([0-9]+[minh]+)_(.*)$","\\1",samples$ID)
samples$timeName = gsub("(R[12])_([0-9]+[minh]+)_(.*)$","\\2",samples$ID)
samples$treatment = gsub("(R[12])_([0-9]+[minh]+)_(.*)$","\\3",samples$ID)
samples$treatment[samples$treatment=="N"]="BRM014"
samples$time= as.numeric(gsub("[a-z]*","",samples$timeName))
samples$time[grepl("min",samples$timeName)]=samples$time[grepl("min",samples$timeName)]/60
```



# Part 1: understanding the experiment

*Now using `samples` make a plot showing the experimental design, with time on the x axis, treatment on the y axis, and one plot on the left and one on the right for the two replicates (e.g. using `facet_grid`).*
  
  ### `#?#` *Make the above plot. Each point should represent one of the samples.  - 1 pt*
```{r}
library(ggplot2)
require(ggplot2)

fig <- ggplot(data = samples, aes(x=time, y=treatment)) + geom_line() + geom_point() + facet_grid(~replicate)
fig

#here, if the point is there, it means such a sample exists, if absent it means that there is no such sample
```

*In this study, one of the things they were comparing was BRM014 to DMSO. The drug BRM014 is dissolved in DMSO, so DMSO alone is the appropriate control to gauge the effect of BRM014.*
  
  
### `#?#` *Can we compare BRM014 to DMSO across all time points? Why/why not?  - 1 pt*
No. DMSO cannot be use as a control because it does not follow the same treatment schedule.

# Part 2: QC

*With most genomics data, it is important both that samples have sufficient coverage, and that the samples have similar coverage. Either case can lead to underpowered analysis, or misleading results. Calcualte the read coverage for each sample. *

### `#?#` Make a plot with read coverage on the y-axis (total number of reads) and the samples on the x-axis. - 3 pt*


```{r}
# there are many ways you could do this; one of which is using the melt/cast functions from reshape
# molten_samples <- melt(atacSeqData, id = c("region"), measured = c(samples$ID))
molten_samples <- melt(atacSeqData)
cast_molten <- cast(molten_samples, variable~., sum)
# rename columns
old_colnames <- colnames(cast_molten)
names(cast_molten)[names(cast_molten) == old_colnames] <- c("sample","read_num")
read_coverage_plt <- ggplot(cast_molten, aes(x = sample, y = read_num)) + geom_col(width = 0.6, position = "dodge")
read_coverage_plt + scale_x_discrete(guide = guide_axis(n.dodge = 4))

```

### `#?#` *Which sample has the most coverage? - 0.5 pt*
R1_24h_DMSO has the most coverage since it has the most number of reads
```{r}
max_read <- cast_molten[which.max(cast_molten$read_num),]
max_read
```

### `#?#` *Which sample has the least? - 0.5 pt*
R1_6h_control has the least coverage since it has the least number of reads
```{r}
min_read <- cast_molten[which.min(cast_molten$read_num),]
min_read
```

### `#?#` *What is the % difference between the max and min (relative to the min)? - 0.5 pt*
```{r}
rel_diff <- (max_read$read_num/min_read$read_num)*100
rel_diff
```

*In cases where samples have vastly different coverage, you can potentially down-sample the higher-coverage samples. Sometimes, throwing out the data in this way can also introduce new problems, so we're going to stick with the data we have.*

*For this assignment, we will look only at BI_protac vs control data. *

### `#?#` *Create a new data.frame containing only the BI_protac and control samples - 1 pt*
```{r}
protac <- atacSeqData[,grepl("BI_protac", names(atacSeqData))]
ctrl <- atacSeqData[,grepl("control", names(atacSeqData))]
protac_ctrl <- cbind(protac,ctrl)

```

### `#?#` *For this subset, calculate the counts per million reads (CPM) for each sample - 2 pt*
```{r}
protac_ctrl_cpm <- data.frame(cpm(protac_ctrl))
protac_ctrl_cpm_melted <- melt(protac_ctrl_cpm)
old_colnames <- colnames(protac_ctrl_cpm_melted)
names(protac_ctrl_cpm_melted)[names(protac_ctrl_cpm_melted) == old_colnames] <- c("sample","CPM")

```


### `#?#` *Plot the kernel density estimate for CPM (x axis). 1 curve per sample, different colours per curve. - 1 pt*

```{r}

ggplot(protac_ctrl_cpm_melted, aes(x = CPM, color = sample)) + geom_density()

```

### `#?#` *Plot the kernel density estimate for log(CPM+1) (x axis), coloured as before - 1 pt*

```{r}
cpm_log_samples <- data.frame(cpm(log1p(protac_ctrl)))
log_cpm_melted <- melt(cpm_log_samples)
old_colnames <- colnames(log_cpm_melted)
names(log_cpm_melted)[names(log_cpm_melted) == old_colnames] <- c("sample","CPM")

ggplot(log_cpm_melted, aes(x = CPM, color = sample)) + geom_density()
```

### `#?#` *Why do you think log-transforming is usually performed when looking at genomics data? What about adding 1 before log transforming? - 2 pt*
Log transforming allows us to look at the data in terms of magnitude, rather than raw counts/reads. This gives a better visualization of the distribution of counts for each sample. 

### `#?#` *Some regions have very large CPMs. Inspect the peaks for which CPM>400. What do you notice about them? 3 pt*
The high CPM's are found in chromosome regions Chr1 and ChrM.

```{r}
region <- atacSeqData[,c("region")]
region_peaks <- cbind(region,protac_ctrl_cpm)
region_peaks <- melt(region_peaks)
old_colnames <- colnames(region_peaks)
names(region_peaks)[names(region_peaks) == old_colnames] <- c("regions","sample","CPM")
large_CPM <- region_peaks[region_peaks$CPM > 400,]
```

*Normally, we would remove some of these regions before continuing (and would redo the above steps). Since this is an assignment, we will continue with the data as-is.*

*Often a good first step is to see if the data look good. One way to do this is by seeing whether or not the signals in each sample correlate with each other in ways you expect.*

### `#?#` *Calculate the pairwise correlations between log(CPM+1)s for the samples and plot them as a heatmap (samples x samples) - 3 pt*
```{r}
pw_cor <- cor(protac_ctrl_cpm, use = "pairwise.complete.obs")
heatmap(pw_cor, scale = "column")

```

### `#?#` *What do you expect the correlations between replicates to look like? Is that what you see? - 2 pt*
The correlation between the same replicates would be high. As expected, the heat map shows high correlation between same replicates, and lower correlation with the other samples other than to itself.  


*It is common to exclude some regions from analysis. For instance, we won't be able to robustly identify those that are differential but have low coverage even if they are truly differential, so there is no point testing these. We will also remove mitochondrial regions, a common contaminant of ATAC-seq data.*


### `#?#` *Filter your data, retaining only regions where the average counts per sample is greater than 10, and also remove mitochondrial regions - 3 pt*
```{r}
region_peaks <- cbind(region,protac_ctrl_cpm)
# find regions with avg CPM per sample is > 10
region_peaks_filtered <- region_peaks[rowMeans(region_peaks[,2:ncol(region_peaks)]) > 10,]
# Get rid of regions that has very large counts of CPM
unique_regions <- unique(large_CPM$regions)
region_peaks_filtered <- region_peaks_filtered[!(region_peaks_filtered$region %in% unique_regions),]

```

### `#?#` *How many peaks did you have before? How many do you have now? - 1 pt*
Before filtering, there are 56617 regions. After there are 28202 regions.

```{r}
before_filter <- nrow(region_peaks)
before_filter
after_filter <- nrow(region_peaks_filtered)
after_filter
```


# Part 3: Differential ATAC

*We want to know what regions are differentially accessible between BI_protac and the control.* 

*Today, we're going to use edgeR, which is designed for RNA-seq, but works well on ATAC-seq as well. The user guide is here:* https://www.bioconductor.org/packages/release/bioc/vignettes/edgeR/inst/doc/edgeRUsersGuide.pdf


### `#?#` *Make a count matrix called `countMatrix` for the BI_protac and control samples, including only the peaks we retained above - 2 pt*
```{r}
countMatrix <- region_peaks_filtered[,2:9]
```

*EdgeR is exceptionally versatile, with many different options for analysis. Today, you're going to use the GLM-quasi-likelihood approach to calculate differential accessibility. We are providing the first example analysis below, which you can modify in subsequent steps. You will need to understand what the steps do, so read the appropriate documentation. *
```{r}
curSamples = samples[match(names(countMatrix), samples$ID),];
y = DGEList(counts=countMatrix, group=curSamples$treatment)
y = calcNormFactors(y)
designPaired = model.matrix(~curSamples$treatment + curSamples$timeName)  
# we are using timeName here to make sure that time is treated as a categorical variable. Had we more time points it might make sense to treat time as a value.
y = estimateDisp(y, designPaired)
fitPaired = glmQLFit(y, designPaired)
qlfPairedTime6vs24 = glmQLFTest(fitPaired, coef=3) 
qlfPairedTreatControlvsProtac = glmQLFTest(fitPaired, coef=2)
allDEStatsPairedTreatControlvsProtac = as.data.frame(topTags(qlfPairedTreatControlvsProtac,n=nrow(countMatrix)))
allDEStatsPairedTreatControlvsProtac$region=row.names(allDEStatsPairedTreatControlvsProtac)
allDEStatsPairedTime6vs24 = as.data.frame(topTags(qlfPairedTime6vs24,n=nrow(countMatrix)))
allDEStatsPairedTime6vs24$region=row.names(allDEStatsPairedTime6vs24)
```
*While the differential analysis has been done in this case, before we look at the results, we are going to check if the data appear to be normalized correctly. Also include a loess line of best fit, and the line y=0.*

### `#?#` *Make an MA plot for allDEStatsPairedTreatControlvsProtac -2pt*
```{r}

ma_plot <- ggplot(allDEStatsPairedTreatControlvsProtac, aes(x = logCPM, y = logFC)) + geom_point()
ma_plot + geom_smooth(method = "loess") + geom_hline(yintercept = 0, colour = "red")

```

### `#?#` *Make an MA plot for allDEStatsPairedTime6vs24 - 1 pt*
```{r}
ma_plot <- ggplot(allDEStatsPairedTime6vs24, aes(x = logCPM, y = logFC)) + geom_point()
ma_plot + geom_smooth(method = "loess") + geom_hline(yintercept = 0, colour = "red")

```

*Now we're going to test loess normalization instead.* 


### `#?#` *Perform the same differential peak analysis using loess regularization. - 1 pt*
```{r}
#Note: the Bioconductor package csaw implements loess regularization in a way that is compatible with edgeR
## Tip: use the csaw library to implement the loess regularization
curSamples = samples[match(names(countMatrix), samples$ID),];
y = DGEList(counts=countMatrix, group=curSamples$treatment)
y = normOffsets(y)
designPaired = model.matrix(~curSamples$treatment + curSamples$timeName)  
# we are using timeName here to make sure that time is treated as a categorical variable. Had we more time points it might make sense to treat time as a value.
y = estimateDisp(y, designPaired)
fitPaired = glmQLFit(y, designPaired)
qlfPairedTime6vs24 = glmQLFTest(fitPaired, coef=3) 
qlfPairedTreatControlvsProtac = glmQLFTest(fitPaired, coef=2)
allDEStatsPairedTreatControlvsProtac_loess_norm = as.data.frame(topTags(qlfPairedTreatControlvsProtac,n=nrow(countMatrix)))
allDEStatsPairedTreatControlvsProtac_loess_norm$region=row.names(allDEStatsPairedTreatControlvsProtac)
allDEStatsPairedTime6vs24_loess_norm = as.data.frame(topTags(qlfPairedTime6vs24,n=nrow(countMatrix)))
allDEStatsPairedTime6vs24_loess_norm$region=row.names(allDEStatsPairedTime6vs24)

```

### `#?#` *Make the same two MA plots as before, but this time using the loess normalized analysis - 1 pt*
```{r}
ctrl_protac_plot_norm <- ggplot(allDEStatsPairedTreatControlvsProtac_loess_norm, aes(x = logCPM, y = logFC)) + geom_point()
ctrl_protac_plot_norm + geom_smooth(method = "loess") + geom_hline(yintercept = 0, colour = "red")

time6vs24_plot_norm <- ggplot(allDEStatsPairedTime6vs24_loess_norm, aes(x = logCPM, y = logFC)) + geom_point()
time6vs24_plot_norm + geom_smooth(method = "loess") + geom_hline(yintercept = 0, colour = "red")

```

### `#?#` *What was the first normalization method? What changed in the MA plots? Which analysis do you think is more reliable and why? - 4 pt*
The first normalization method is the TMM method, which is the weighted trimmed mean of the log expression ratios. This method assumes that most of the genes are not differentially expressed. In comparison to using Loess normalization, Loess removes the bias by looking for outlier and weights those data points down. So in the MA plots for protac vs control, we see that the data is now symmetrical around y = 0, and that the non-linear bias is weighted down. Since we want to look at significance between samples, TMM would be a great choice for removing batch effects while comparing the sampels from different treatments. However, if we look at the plots above, clearly Loess provides the best normalization as the best line of fit matches closest to the horizontal line. 


# Part 4: GC bias

*Next, we will look at potential GC bias in the data. We will again use bioconductor *

### `#?#` *Convert the region IDs to a GRanges object - 3 pt*
```{r}
#note that the names of your peaks are of the format <chr>:<startPos>-<endPos>
## Tip: lookinto the GenomicRanges documentation

# transform region ID's into 3 columns: chr, start, end
region_IDs <- data.frame(region_peaks_filtered$region)
split_chr <-  data.frame(do.call("rbind",strsplit(as.character(region_IDs$region_peaks_filtered.region), ":", fixed = TRUE)))
split_startend <- data.frame(do.call("rbind",strsplit(as.character(split_chr$X2), "-", fixed = TRUE)))
region_IDs_processed <- cbind(split_chr$X1,split_startend)
old_colnames <- colnames(region_IDs_processed)
names(region_IDs_processed)[names(region_IDs_processed) == old_colnames] <- c("chr","start","end")

# create granges object
g_range_region <- GRanges(region_IDs_processed)


```



### `#?#` *Extract the genomic DNA sequences for each peak using hg38 - 3 pt*
*See for relevant documentation: https://bioconductor.org/packages/release/workflows/vignettes/sequencing/inst/doc/sequencing.html *
```{r}
## Tip: Use the Biostring library 

library(BSgenome.Hsapiens.UCSC.hg38)

chr_dna <- getSeq(BSgenome.Hsapiens.UCSC.hg38, g_range_region)
GC_peak <- letterFrequency(chr_dna, "GC", as.prob = TRUE)

```


*Now we will see if there's any relationship between peak CPM and GC content for each of the samples.*

### `#?#` *Create scatter plots (one per sample, e.g. using facet_wrap), including lines of best fit (GAM), where each plot shows GC content (x axis) vs CPM (y axis) for each peak (points) -2pt*
```{r}
#please limit the y axis to between 0 and 50 
sample_id <- colnames(protac_ctrl)
gc_region <- data.frame(GC_peak,GC_peak,GC_peak,GC_peak,GC_peak,GC_peak,GC_peak,GC_peak)
old_colnames <- colnames(gc_region)
names(gc_region)[names(gc_region) == old_colnames] <- sample_id
gc_region <- melt(gc_region)
old_colnames <- colnames(gc_region)
names(gc_region)[names(gc_region) == old_colnames] <- c("sample","GC")
gc_cpm_data <- cbind(melt(region_peaks_filtered),gc_region$GC)

gc_cpm_fig <- ggplot(data = gc_cpm_data, aes(x = gc_region$GC, y = value)) + geom_smooth(method = "gam") + geom_point() + ylim(0,50) + facet_wrap(~variable) + xlab('GC (%)') + ylab("CPM")
gc_cpm_fig

```

### `#?#` *Repeat the above, but this time showing only the lines of best fit and all on the same plot - 2 pt*
```{r}
gc_cpm_best_fit_fig <- ggplot(data = gc_cpm_data, aes(x = gc_region$GC, y = value, color = variable)) + geom_smooth(method = "gam") + ylim(0,50) + xlab('GC (prob)') + ylab('CPM')
gc_cpm_best_fit_fig
```


### `#?#` *Given this result, predict whether we will see a significant relationship between GC content and logFC in our differential peak analysis (loess-normalized). Justify your prediction. Predicting "wrong" will not be penalized, as long as your justification is correct. Don't retroactively change your answer. - 2 pt*
Given the plot above, we see that the CPM for each sample at different GC content follows similar trends. However, the fold change (FC) can visually represent magnitude changes better. From the plot, we see that there will most likely be a significant relationship between the GC content and the log fold change.

### `#?#` *Plot the relationship between GC and logFC for the loess-normalized ControlvsProtac analysis. Also include a line of best fit (blue) and y=0 (red) - 2 pt*
```{r}
control_protac_norm_gc <- cbind(allDEStatsPairedTreatControlvsProtac_loess_norm,data.frame(GC_peak))

gc_logFC_norm_fig <- ggplot(control_protac_norm_gc, aes(x=G.C,y=logFC)) 
gc_logFC_norm_fig + geom_smooth(method = "loess") + geom_hline(yintercept = 0, colour = "red")

```

### `#?#` *Now plot the same thing for the NON loess-normalized ControlvsProtac analysis. - 1 pt*
```{r}
control_protac_gc <- cbind(allDEStatsPairedTreatControlvsProtac,data.frame(GC_peak))

gc_logFC_fig <- ggplot(control_protac_gc, aes(x=G.C,y=logFC)) 
gc_logFC_fig + geom_smooth(method = "loess") + geom_hline(yintercept = 0, colour = "red")

```


### `#?#` *Was your prediction correct? Do you think we should also account for GC normalization in our differential ATAC analysis? Why/why not? - 3 pt*
Yes. There seems to be a significant relationship between the GC content with the logFC, as we see that there is a non-linear trend where the logFC changes with GC content. If GC normalization means to use loess to normalize the FC, then yes it should be taken into account in the differential ATAC analysis since it will reduce bias in the data analysis.


*We will leave GC normalization as an optional exercise, and will not actually do it here.*

# Part 5: Differential analysis results

### `#?#` *Suppose we perform the analyses above, redoing the differential analysis once more with GC normalization, and also considering that we tested loess and the default normalization methods. Did we P-hack? Why or why not? - 2 pt*
We did a little bit of P-hacking. Throughout the analysis, we were focusing on finding patterns from a single data set, through a combination of filtering and normalization procedures to reduce noise and bias. 


*Going forward, we will only use the initial analysis (**not loess normalized**)*

### `#?#` *Now considering the two comparisons (6 vs 24 hours, and protac vs control). EdgeR performed a correction for MHT, but if we want to analyze the results from both comparisons, do we need to re-adjust to account for the fact that we tested two different hypothesis sets (time and treatment)? Why/not? - 2 pt*
Yes, we would need to re-adjust to account for the the different treatment times (6h vs 24h). We need to include paired testing between control and treatment for 6 hr and a paired testing between control and treatment for 24 hr group.


### `#?#` *How many differential peaks did you find (FDR<0.01). - 1 pt*
For 6 vs 24 hour test there are two differential peaks.
For Protac vs control there are 355 differential peaks.


```{r}
diff_peaks_6v24 <- nrow(allDEStatsPairedTime6vs24[allDEStatsPairedTime6vs24$FDR<0.01,])
diff_peaks_6v24

diff_peaks_ctrlvprotac <- nrow(allDEStatsPairedTreatControlvsProtac[allDEStatsPairedTreatControlvsProtac$FDR<0.01,])
diff_peaks_ctrlvprotac

```

### `#?#` *Make a volcano plot of the allDEStatsPairedTreatControlvsProtac, with -log10(p-value) on the y axis and logFC on the x. Colour points that are significant at an FDR<0.01. - 2 pt*
```{r}

volcano_plot <- ggplot(data = data.frame(x = allDEStatsPairedTime6vs24$logFC, y = -log10(allDEStatsPairedTime6vs24$PValue), FDR = allDEStatsPairedTime6vs24$FDR), aes(x = x, y = y)) + geom_point(aes(colour = FDR < 0.01))
volcano_plot

```




### `#?#` *Plot the logCPM (x axis) by -log10(Pvalue) (y axis), again colouring by FDR<0.01. - 2 pt*
```{r}
volcano_plot_2 <- ggplot(data = data.frame(x = allDEStatsPairedTime6vs24$logCPM, y = -log10(allDEStatsPairedTime6vs24$PValue), FDR = allDEStatsPairedTime6vs24$FDR), aes(x = x, y = y)) + geom_point(aes(colour = FDR < 0.01)) + xlab('logCPM') + ylab('log(P-Value)')
volcano_plot_2

```


### `#?#` *Do you think our initial filtering on peaks with at least 10 reads on average per sample was a good choice? Why or why not?*
The threshold seems arbitrary. Given that we filtered based on at least 10 reads, filtering 20, 30, etc., may give different answers. However, if the threshold was found through a substantial methods, it would be a good choice. 


*At this point there are many other follow ups you can and would do for a real differential analysis, but we leave these as optional exercises. For example:*
1. Confirming that the differential peaks look correct (e.g. CPM heatmap)
2. Confirming that peaks look differential on the genome browser
3. Looking for motif enrichment
4. Performing a GREAT analysis, including functional enrichment and assigning peaks to genes

*Knit your assignment as a github_document and submit the resulting .md and this .Rmd to your github, and complete the assignment submission on Canvas. Make sure to include the graphs with your submission. *
 



# Authors and contributions

Following completion of your assignment, please fill out this section with the authors and their contributions to the assignment.  If you worked alone, only the author (e.g. your name and student ID) should be included.

Authors: Jason Fung (44362648) and Ariel Huynh (73423899)

Contributions: Jason and Ariel both worked on the same computer. Ariel researched answers to comprehension and analysis questions, while Jason plotted and processed the data. After each data was plotted, Ariel would analyze the plots and give the interpretation. 
  